{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceNET\n",
    "### Docker\n",
    "docker run --gpus all -it -p 8888:8888 -v /media/v1pi/DATA/DOCUMENTS/Workspaces:/tf/Workspaces -w /tf/Workspaces  tensorflow/tensorflow:latest-gpu-py3-jupyter\n",
    "### Dependencies\n",
    "apt-get update <br>\n",
    "apt-get install cmake libsm6 libxext6 libxrender-dev <br>\n",
    "pip3 install opencv-python dlib requests keras tensorflow_hub sklearn tqdm pandas <br>\n",
    "pip3 install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html <br>\n",
    "pip3 install tensorflowjs --no-deps <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from preprocess import init_pre_proccess\n",
    "import tensorflowjs as tfjs\n",
    "from numpy import savez_compressed\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define triplet_loss function\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.3):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,\n",
    "               positive)), axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, \n",
    "               negative)), axis=-1)\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "   \n",
    "    return loss\n",
    "\n",
    "# Export model to tfjs\n",
    "def save_to_tfjs(model):\n",
    "    #tfjs.converters.save_keras_model(model, os.path.join(ROOT_PATH, 'models', 'tfjs'))\n",
    "    tfjs.converters.save_keras_model(model, os.path.join(ROOT_PATH, 'models', 'tfjs'))\n",
    "\n",
    "# Export to model format\n",
    "def save_model(model, name='model1'):\n",
    "    pathModel = os.path.join(ROOT_PATH, 'models', 'faceNET', '{0}.json'.format(name))\n",
    "    pathWeights = os.path.join(ROOT_PATH, 'models', 'faceNET', '{0}.h5'.format(name))\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(pathModel, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(pathWeights)\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "# load json and create model\n",
    "def load_model_from_json(name='model1'):\n",
    "    pathModel = os.path.join(ROOT_PATH, 'models', 'faceNET', '{0}.json'.format(name))\n",
    "    pathWeights = os.path.join(ROOT_PATH, 'models', 'faceNET', '{0}.h5'.format(name))\n",
    "    json_file = open(pathModel, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(pathWeights)\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n",
    "\n",
    "def load_model(name='model1'):\n",
    "    pathModel = os.path.join(ROOT_PATH, 'models', 'FaceNET-Keras', '{0}.h5'.format(name))\n",
    "    pathWeights = os.path.join(ROOT_PATH, 'models', 'FaceNET-Keras', '{0}_weights.h5'.format(name))\n",
    "    loaded_model = tf.keras.models.load_model(pathModel)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(pathWeights)\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_is_it(image, database, model):\n",
    "    encoding = img_to_encoding(image, model)\n",
    "    \n",
    "    min_dist = 100\n",
    "    identity = None\n",
    "    \n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        dist = np.linalg.norm(db_enc - encoding)\n",
    "        print('distance for %s is %s' %(name, dist))\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    \n",
    "    if min_dist > 0.55:\n",
    "        return None\n",
    "    else:\n",
    "        return identity\n",
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = np.expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]\n",
    "\n",
    "def img_to_encoding(image_path, model):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    #img = img1[...,::-1]\n",
    "    #img = np.reshape(img1, (3,96,96))\n",
    "    \n",
    "    #x_train = np.array([img])\n",
    "    #embedding = model.predict_on_batch(x_train)\n",
    "    return get_embedding(model, img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Get current path\n",
    "ROOT_PATH = os.path.dirname(os.path.realpath('__file__'))\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/100124/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/25245/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/25316/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/25540/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/10990/7.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/7469/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1123401/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1123401/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1646/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2231/9.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/87919/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/87919/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/87942/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/65920/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/6593/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/12041/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1206334/6.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/13565/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/108719/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/108719/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/568555/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/821/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1733/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1733/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1733/6.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1733/7.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1733/8.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/29396/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/34590/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1164646/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/124643/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1248374/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/69764/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1864983/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/5563/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/41639/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/4165/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/19549/10.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/19549/13.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/19549/14.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1959290/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/4786/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/47882/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1566805/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/21684/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/581673/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/5833/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/96657/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/971388/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/85/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/3776/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/3776/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/9045/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/90572/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/90633/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/9076/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/9110/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/912/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/11449/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/30616/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/309/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/5602/6.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/7219/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/722/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1832851/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1594612/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1599859/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2405/7.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/61903/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/61903/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/6463/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/167411/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/6232/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/63128/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1245/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1337/5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1898026/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1898026/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2637/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2641/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/94814/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1986576/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2205098/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/221611/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/221773/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/221773/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/5729/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/57298/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/9277/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/21411/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/119143/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/231909/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2320/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/588/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/7351/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/73968/8.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/30003/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/30155/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/38562/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/11127/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/11705/26.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/42171/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/89609/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/89670/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/89670/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1809206/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2096/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1445849/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1445869/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/3142/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/528/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/12928/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/12928/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1254671/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1254671/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1255318/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1035/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2492365/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/9577/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1844/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/39741/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/40009/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/40009/6.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/40009/7.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/13726/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/82702/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/82885/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/3664/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/368/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/81244/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/155282/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/7908/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/43259/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/50/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/5530/9.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/20405/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/205/12.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/205/13.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/205/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/218176/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1647636/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1650712/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/148497/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/945/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/97698/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/18892/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/4110/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/7570/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/76126/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/54422/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/54564/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/53487/1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/53487/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/538166/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/776/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/77921/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/42705/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/4273/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/43120/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/17380/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/206483/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2074587/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2074587/6.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1309253/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/10980/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/584/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/585/11.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/58508/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/57700/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/63571/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/6384/12.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1240646/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/19767/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1459772/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/87120/8.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/8727/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/8727/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/60073/34.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2194273/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/932967/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/12214/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1197569/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/146750/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1378866/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1378866/8.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/115876/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1160546/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/35742/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/7120/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/56890/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/5695/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/571418/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1252824/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/22735/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/13637/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/13637/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/136487/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/100993/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2371446/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/230660/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2084790/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/5026/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/5041/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/88873/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/95476/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/955809/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1108/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/11084/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1108859/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/96283/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/65730/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/7447/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/18197/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/51969/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/25655/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/14782/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1210634/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1212803/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/16350/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/19034/15.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1905/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/103994/12.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/691/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/89903/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/9015/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/90135/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/11850/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1185787/2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/115788/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1181313/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1150/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/3366/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/33698/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/148615/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1687041/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1691282/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1948459/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1948459/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/6250/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/6250/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/2034/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/32327/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1289776/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/12899/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/131820/5.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/15736/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/15757/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/12978/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/97880/8.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/9789/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/98078/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1336/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/8606/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/7710/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/11993/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/12021/4.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1996905/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/63544/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/6355/2.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/223901/3.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/1243/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/124495/1.jpg\n",
      "WARNING:preprocess:Skipping filename: /tf/Workspaces/DeepLearning/ai-how-is/Python/images/train/25165/1.jpg\n",
      "INFO:preprocess:Completed in 910.2716233730316 seconds\n"
     ]
    }
   ],
   "source": [
    "# Preprocess images\n",
    "init_pre_proccess(os.path.join(ROOT_PATH, 'images', 'train'), os.path.join(ROOT_PATH, 'output', 'train'), 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocess:Completed in 6.556511878967285 seconds\n"
     ]
    }
   ],
   "source": [
    "init_pre_proccess(os.path.join(ROOT_PATH, 'images', 'test'), os.path.join(ROOT_PATH, 'output', 'test'), 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "frModel = load_model('facenet_keras')\n",
    "#frModel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(actor, model, type_mode = 'train'):\n",
    "    image_paths = []\n",
    "    for ext in ('*.jpeg', '*.jpg', '*.png'):        \n",
    "        image_paths.extend(glob.glob(os.path.join(ROOT_PATH, 'output', type_mode, actor, ext)))\n",
    "    \n",
    "    results = []\n",
    "    for image in image_paths:\n",
    "        encoding = img_to_encoding(image, model)\n",
    "        results.append(encoding)\n",
    "    return np.array(results)\n",
    "\n",
    "def test_data(actor, database, model):\n",
    "    images = []\n",
    "    for ext in ('*.jpeg', '*.jpg', '*.png'):\n",
    "        images.extend(glob.glob(os.path.join(ROOT_PATH, 'output', 'test', actor, ext)))\n",
    "    for image in images:\n",
    "        print(who_is_it(image, database, model))\n",
    "\n",
    "def read_database_ids(filename):\n",
    "    actors_ids = []\n",
    "    with open(filename) as f:\n",
    "        actors_ids = [line.rstrip() for line in f]\n",
    "    return actors_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoding_database(database_name, type_mode= 'train'):\n",
    "    database = {}\n",
    "    actors_ids = read_database_ids(os.path.join(ROOT_PATH, 'database', database_name))\n",
    "    total_actors = int(actors_ids[0])\n",
    "    with tqdm(total= total_actors) as pbar:\n",
    "        for actor_id in actors_ids[1:]:\n",
    "            actor_dir = os.path.join(ROOT_PATH, 'output', type_mode, actor_id)\n",
    "            if os.path.isdir(actor_dir) and len(os.listdir(actor_dir)) != 0:\n",
    "                database[actor_id] = train(actor_id, frModel, type_mode)\n",
    "            pbar.update(1)\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_database(database):\n",
    "    labels = []\n",
    "    values = []\n",
    "    for key, value in database.items():    \n",
    "        for v in value:\n",
    "            values.append(np.reshape(v, [128]))\n",
    "            labels.append(np.array([key]))\n",
    "    labels = np.array(labels)\n",
    "    values = np.array(values)\n",
    "    return values, labels, list(database.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_processed_data(database_ids_name, processed_file_name, type_mode='train'):\n",
    "    database = create_encoding_database(database_ids_name, type_mode)\n",
    "    values, labels, classes = preprocess_database(database)\n",
    "    str_date_now = datetime.today().strftime('%d-%m-%Y')\n",
    "    savez_compressed(os.path.join(ROOT_PATH, 'processed', '{0}_{1}_embeddings.npz'.format(processed_file_name,str_date_now)), values, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a576d444884ea8ac00cefb5559fdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9501.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cria o BD Encoding de treino\n",
    "create_processed_data('database_13-06-2020', 'trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe81b8b1649e49c68cf75d10acef85d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cria o BD Encoding de teste\n",
    "create_processed_data('test_database_13-06-2020', 'test', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carergando os dados do BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(os.path.join(ROOT_PATH, 'processed', 'trained_13-06-2020_embeddings.npz'), allow_pickle=True) as f:\n",
    "    values, labels, classes = f['arr_0'], f['arr_1'], f['arr_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(os.path.join(ROOT_PATH, 'processed', 'test_13-06-2020_embeddings.npz'), allow_pickle=True) as f:\n",
    "    values_test, labels_test = f['arr_0'], f['arr_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificando com SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_encoder = Normalizer(norm='l2')\n",
    "x_train = in_encoder.transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(labels)\n",
    "y_train = out_encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = in_encoder.transform(values_test)\n",
    "y_test = out_encoder.transform(labels_test)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.predict_proba([x_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classficando com Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_model(n_classes):\n",
    "    input_shape = Input(shape=(128))  \n",
    "    out = Dense(256, activation='relu')(input_shape)\n",
    "    out = Dense(512, activation='relu')(out)\n",
    "    out = Dense(n_classes, activation='softmax')(out)\n",
    "    \n",
    "    model = Model(input_shape, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.reshape(classes, (n_classes,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dummies = pd.get_dummies(classes)\n",
    "classes_ids = classes_dummies.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_real = np.array([classes_ids.index(x) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train_real, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_real = np.array([classes_ids.index(x) for x in labels_test])\n",
    "y_test = to_categorical(y_test_real, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer():\n",
    "    return SGD(lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_encoder = Normalizer(norm='l2')\n",
    "x_train = in_encoder.transform(values)\n",
    "x_test = in_encoder.transform(values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'classification9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 17870 samples, validate on 28 samples\n",
      "Epoch 1/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 2.2629 - accuracy: 0.5517 - val_loss: 1.2044 - val_accuracy: 0.7857\n",
      "Epoch 2/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 1.4892 - accuracy: 0.6497 - val_loss: 1.6773 - val_accuracy: 0.6786\n",
      "Epoch 3/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 0.8560 - accuracy: 0.7992 - val_loss: 0.9602 - val_accuracy: 0.7143\n",
      "Epoch 4/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 0.4180 - accuracy: 0.9204 - val_loss: 0.4681 - val_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 0.2118 - accuracy: 0.9602 - val_loss: 0.5046 - val_accuracy: 0.8929\n",
      "Epoch 6/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 0.1143 - accuracy: 0.9804 - val_loss: 0.3172 - val_accuracy: 0.9286\n",
      "Epoch 7/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 0.0645 - accuracy: 0.9914 - val_loss: 0.6262 - val_accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 0.0405 - accuracy: 0.9950 - val_loss: 0.3279 - val_accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 0.0269 - accuracy: 0.9972 - val_loss: 0.2296 - val_accuracy: 0.9643\n",
      "Epoch 10/10\n",
      "17870/17870 [==============================] - 27s 1ms/sample - loss: 0.0179 - accuracy: 0.9985 - val_loss: 0.2811 - val_accuracy: 0.9643\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7720)              3960360   \n",
      "=================================================================\n",
      "Total params: 4,124,968\n",
      "Trainable params: 4,124,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "try:\n",
    "    model_tf = load_model_from_json(model_name)\n",
    "except:\n",
    "    model_tf = create_classification_model(n_classes)\n",
    "model_tf.compile(optimizer=optimizer(),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy']\n",
    "          )\n",
    "model_tf.fit(x_train, y_train, batch_size=batch_size, epochs=10, validation_data=(x_test,y_test),verbose=1)\n",
    "model_tf.summary()\n",
    "save_model(model_tf, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "28/28 [==============================] - 0s 9ms/sample - loss: 0.2811 - accuracy: 0.9643\n",
      "Accuracy: 96.43% | Loss: 0.28114\n"
     ]
    }
   ],
   "source": [
    "model = load_model_from_json(model_name)\n",
    "model.compile(optimizer=optimizer(),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy']\n",
    "          )\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100), \"| Loss: %.5f\" % (scores[0]))\n",
    "result = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predicts(data, answer, classes_ids):\n",
    "    count = 0\n",
    "    for d in data:\n",
    "        pos = np.argmax(d)\n",
    "        predict_answer = classes_ids[pos]  \n",
    "        pos = np.argmax(answer[count])\n",
    "        new_answer = classes_ids[pos]\n",
    "        print('expected {0} received {1}'.format(new_answer, predict_answer))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected 131 received 131\n",
      "expected 131 received 131\n",
      "expected 131 received 131\n",
      "expected 131 received 131\n",
      "expected 1245 received 1245\n",
      "expected 1245 received 1245\n",
      "expected 1245 received 1245\n",
      "expected 1245 received 1245\n",
      "expected 1339 received 1339\n",
      "expected 1339 received 1339\n",
      "expected 1339 received 1339\n",
      "expected 1339 received 1339\n",
      "expected 1276 received 1276\n",
      "expected 1276 received 1276\n",
      "expected 1276 received 1276\n",
      "expected 1276 received 1276\n",
      "expected 1331 received 1331\n",
      "expected 1331 received 1331\n",
      "expected 1331 received 1331\n",
      "expected 1331 received 1331\n",
      "expected 1909 received 1909\n",
      "expected 1909 received 1909\n",
      "expected 1909 received 1909\n",
      "expected 1909 received 14886\n",
      "expected 1665 received 1665\n",
      "expected 1665 received 1665\n",
      "expected 1665 received 1665\n",
      "expected 1665 received 1665\n"
     ]
    }
   ],
   "source": [
    "show_predicts(result, y_test, classes_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathModel = os.path.join(ROOT_PATH, 'database', 'classes_ids')\n",
    "\n",
    "teste = ''\n",
    "for classes in classes_ids:\n",
    "    teste += classes + '\\n'\n",
    "\n",
    "with open(pathModel, \"w\") as file:\n",
    "    file.write(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.4r1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfjs.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
